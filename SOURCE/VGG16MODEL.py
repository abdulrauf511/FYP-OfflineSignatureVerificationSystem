# -*- coding: utf-8 -*-
"""Copy of  VGG16_custom.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ACaK_bMPkdfQ9lCA-M4ysyMYKasP6AjT
"""

from google.colab import drive
import zipfile
import pandas as pd
import os
import numpy as np
from PIL import Image
import cv2
import matplotlib.pyplot as plt
from skimage.io import imread, imshow
from skimage.transform import resize
import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from google.colab import drive
import numpy as np
import itertools
from tensorflow.keras.models import load_model
import keras
import csv
from PIL import Image
from keras import backend as K
from tensorflow.keras.utils import plot_model
from tensorflow.keras.applications import VGG16

zip_ref = zipfile.ZipFile('/content/drive/MyDrive/FYP/FINAL_SIGNS_PROCESSED.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

from google.colab import drive
drive.mount('/content/drive')

train_df = pd.read_csv("/content/drive/MyDrive/FYP/FINAL_4_TRAIN.csv")
test_df = pd.read_csv("/content/drive/MyDrive/FYP/FINAL_4_TEST.csv")

train_df.columns = ["GENUINE1", "GENUINE2", "GENUINE3", "GENUINE4", "TEST", "OUTCOME", "SET"]
test_df.columns = ["GENUINE1", "GENUINE2", "GENUINE3", "GENUINE4", "TEST", "OUTCOME", "SET"]

train_df

SIGN_PATH = "/content/FINAL_SIGNS/"

x_train_list=[]
with open('/content/drive/MyDrive/FYP/FINAL_4_TRAIN.csv', 'r') as csvfile:
    csvreader = csv.reader(csvfile)
    for row in csvreader:
       img1 = plt.imread(SIGN_PATH + row[0])
       img1=resize(img1,(118,118,3))
       x_train_list.append(img1)
       img2 = plt.imread(SIGN_PATH + row[1])
       img2=resize(img2,(118,118,3))
       x_train_list.append(img2)
       img3 = plt.imread(SIGN_PATH + row[2])
       img3=resize(img3,(118,118,3))
       x_train_list.append(img3)
       img4 = plt.imread(SIGN_PATH + row[3])
       img4=resize(img4,(118,118,3))
       x_train_list.append(img4)
       img5 = plt.imread(SIGN_PATH + row[4])
       img5=resize(img5,(118,118,3))
       x_train_list.append(img5)

print("X Train list:", x_train_list)
x_train_arr = np.array(x_train_list)
print("X TRAIN array:", x_train_arr)
x_train_arr.shape

y_train_list=[]
with open('/content/drive/MyDrive/FYP/FINAL_4_TRAIN.csv', 'r') as csvfile:
    csvreader = csv.reader(csvfile)
    for row in csvreader:
        y_train_list.append(row[5])
print("Y Train list:", y_train_list)
y_train_arr = np.array(y_train_list)
print("Y TRAIN array:", y_train_arr)
y_train_arr.shape

x_test_list=[]
with open('/content/drive/MyDrive/FYP/FINAL_4_TEST.csv', 'r') as csvfile:
    csvreader = csv.reader(csvfile)
    for row in csvreader:
        img1 = plt.imread(SIGN_PATH + row[0])
        img1=resize(img1,(118,118,3))
        x_test_list.append(img1)
        img2 = plt.imread(SIGN_PATH + row[1])
        img2=resize(img2,(118,118,3))
        x_test_list.append(img2)
        img3 = plt.imread(SIGN_PATH + row[2])
        img3=resize(img3,(118,118,3))
        x_test_list.append(img3)
        img4 = plt.imread(SIGN_PATH + row[3])
        img4=resize(img4,(118,118,3))
        x_test_list.append(img4)
        img5 = plt.imread(SIGN_PATH + row[4])
        img5=resize(img5,(118,118,3))
        x_test_list.append(img5)

print("X TEST list:", x_test_list)
x_test_arr = np.array(x_test_list)
print("X TEST array:", x_test_arr)
x_test_arr.shape

y_test_list=[]
with open('/content/drive/MyDrive/FYP/FINAL_4_TEST.csv', 'r') as csvfile:
    csvreader = csv.reader(csvfile)
    for row in csvreader:
        y_test_list.append(row[5])
print("Y TEST list:", y_test_list)
y_test_arr = np.array(y_test_list)
print("Y TEST array:", y_test_arr)
y_test_arr.shape

def euclidean_distance(vectors):
    x, y = vectors
    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)
    return tf.sqrt(tf.maximum(sum_square, K.epsilon()))

def eucl_dist_output_shape(shapes):
    shape1, shape2 = shapes
    return (shape1[0], 1)

from tensorflow.keras.layers import Input, Flatten, Dense, Lambda
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG16
import tensorflow as tf

def create_model(input_shape):
    Depth = 64

    # Load the VGG16 model without the top classification layers
    vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)

    # Freeze the pre-trained weights so they are not updated during training
    for layer in vgg16_base.layers:
        layer.trainable = False

    # Create the multiple input branches
    one_input = Input(shape=input_shape, name='one_input')
    one_branch = vgg16_base(one_input)
    one_output = Flatten()(one_branch)

    two_input = Input(shape=input_shape, name='two_input')
    two_branch = vgg16_base(two_input)
    two_output = Flatten()(two_branch)

    three_input = Input(shape=input_shape, name='three_input')
    three_branch = vgg16_base(three_input)
    three_output = Flatten()(three_branch)

    four_input = Input(shape=input_shape, name='four_input')
    four_branch = vgg16_base(four_input)
    four_output = Flatten()(four_branch)

    five_input = Input(shape=input_shape, name='five_input')
    five_branch = vgg16_base(five_input)
    five_output = Flatten()(five_branch)

    # Compute the average of the output branches
    average = Lambda(lambda x: tf.reduce_mean(x, axis=0))([one_output, two_output, three_output, four_output])

    # Compute the distance between the average and the fifth output branch
    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([average, five_output])

    dense = Dense(64, activation='relu')(distance)
    output = Dense(1, activation='sigmoid', name='output')(dense)

    # Create the final model
    model = Model(inputs=[one_input, two_input, three_input, four_input, five_input], outputs=[output])

    return model

# Define the input shape
input_shape = (118, 118, 3)

# Create the model
model = create_model(input_shape)

# Print the model summary
model.summary()

# Plot the model architecture
plot_model(model, to_file='model.png', show_shapes=True)

def MakePairs(X, Y):
    X_pairs, Y_pairs = [], []
    pair_count = 0
    for i in range(0, len(X) - 4, 5):
        image_A = X[i]
        image_B = X[i + 1]
        image_C = X[i + 2]
        image_D = X[i + 3]
        image_E = X[i + 4]
        X_pairs.append([image_A, image_B, image_C, image_D, image_E])
        pair_count += 1
        """
        plt.figure()
        plt.subplot(151)
        plt.imshow(image_A)
        plt.title('Image A')
        plt.subplot(152)
        plt.imshow(image_B)
        plt.title('Image B')
        plt.subplot(153)
        plt.imshow(image_C)
        plt.title('Image C')
        plt.subplot(154)
        plt.imshow(image_D)
        plt.title('Image D')
        plt.subplot(155)
        plt.imshow(image_E)
        plt.title('Image E')
        plt.show()
        """
    for j in range(0, len(X_pairs)):
        Y_pairs.append(Y[j])
    X_pairs = np.array(X_pairs)
    Y_pairs = np.array(Y_pairs)
    print(f'Total pairs made: {pair_count}')
    return X_pairs, Y_pairs

X_train_pairs,Y_train_pairs=MakePairs(x_train_arr,y_train_arr)
X_train_pairs.shape,Y_train_pairs.shape
Y_train_pairs=Y_train_pairs.astype(float)
X_train_pairs.shape,Y_train_pairs.shape

X_test_pairs,Y_test_pairs=MakePairs(x_test_arr, y_test_arr)
X_test_pairs.shape,Y_test_pairs.shape
Y_test_pairs=Y_test_pairs.astype(float)
X_test_pairs.shape,Y_test_pairs.shape

from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# Define the contrastive loss function
def contrastive_loss(y_true, y_pred):
    margin = 1
    return tf.reduce_mean(y_true * tf.square(y_pred) + (1 - y_true) * tf.square(tf.maximum(margin - y_pred, 0)))

optimizer = RMSprop(learning_rate=1e-5, rho=0.9, epsilon=1e-08)

model.compile(loss=contrastive_loss, optimizer=optimizer)

callbacks = [
    EarlyStopping(patience=12, verbose=1),
    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1),
    ModelCheckpoint('/content/drive/MyDrive/FYP/SALEEM/siamese-sigcom-{epoch:03d}.h5', verbose=1, save_weights_only=True)
]

history = model.fit(
    [X_train_pairs[:, 0, :, :, :], X_train_pairs[:, 1, :, :, :], X_train_pairs[:, 2, :, :, :], X_train_pairs[:, 3, :, :, :], X_train_pairs[:, 4, :, :, :]],
    Y_train_pairs,
    validation_data=(
        [X_test_pairs[:, 0, :, :, :], X_test_pairs[:, 1, :, :, :], X_test_pairs[:, 2, :, :, :], X_test_pairs[:, 3, :, :, :], X_test_pairs[:, 4, :, :, :]],
        Y_test_pairs
    ),
    epochs=1000,
    batch_size=10,
    callbacks=callbacks
)

model.load_weights('/content/drive/MyDrive/FYP/siamese-sigcom-019.h5')

im=106
img_A = imread(os.path.join(SIGN_PATH, test_df["GENUINE1"][im]))
img_B = imread(os.path.join(SIGN_PATH, test_df["GENUINE2"][im]))
img_C = imread(os.path.join(SIGN_PATH, test_df["GENUINE3"][im]))
img_D = imread(os.path.join(SIGN_PATH, test_df["GENUINE4"][im]))
img_E = imread(os.path.join(SIGN_PATH, test_df["TEST"][im]))

label_A = y_test_arr[im]
label_B = y_test_arr[im]
label_C = y_test_arr[im]
label_D = y_test_arr[im]
label_E = y_test_arr[im]

img_A = resize(img_A, (118, 118, 3))
img_B = resize(img_B, (118, 118, 3))
img_C = resize(img_C, (118, 118, 3))
img_D = resize(img_D, (118, 118, 3))
img_E = resize(img_E, (118, 118, 3))

import numpy as np
def compute_accuracy_roc(predictions, labels):
    print(predictions)
    num_pairs = len(labels)
    num_images_per_pair = 5

    nsame = np.sum(labels == 1)
    ndiff = np.sum(labels == 0)

    labels = np.repeat(labels, num_images_per_pair)

    dmax = np.max(predictions)
    dmin = np.min(predictions)

    step = 0.01
    max_acc = 0
    best_thresh = -1

    for d in np.arange(dmin, dmax + step, step):
        idx1 = predictions <= d
        idx2 = predictions > d

        tp = 0
        fp = 0
        tn = 0
        fn = 0

        for i in range(num_pairs):
            pair_start = i * num_images_per_pair
            pair_end = (i + 1) * num_images_per_pair
            if np.all(labels[pair_start:pair_end] == 1):
                tp += np.sum(idx1[pair_start:pair_end])
                fn += np.sum(idx2[pair_start:pair_end])
            else:
                fp += np.sum(idx1[pair_start:pair_end])
                tn += np.sum(idx2[pair_start:pair_end])

        acc = float(tp + tn) / (tp + tn + fp + fn)

        if acc > max_acc:
            max_acc = acc
            best_thresh = d
    return max_acc, best_thresh

import numpy as np
import matplotlib.pyplot as plt

def compute_accuracy(predictions, labels, thresholds):
    num_pairs = len(labels)
    num_images_per_pair = 5

    nsame = np.sum(labels == 1)
    ndiff = np.sum(labels == 0)

    labels = np.repeat(labels, num_images_per_pair)

    accuracies = []
    if isinstance(thresholds, list):
        for threshold in thresholds:
            idx1 = predictions > threshold
            idx2 = predictions <= threshold

            tp = 0
            fn = 0
            fp = 0
            tn = 0

            for i in range(num_pairs):
                pair_start = i * num_images_per_pair
                pair_end = (i + 1) * num_images_per_pair

                if np.all(labels[pair_start:pair_end] == 1):
                    tp += np.sum(idx1[pair_start:pair_end])
                    fn += np.sum(idx2[pair_start:pair_end])
                else:
                    fp += np.sum(idx1[pair_start:pair_end])
                    tn += np.sum(idx2[pair_start:pair_end])

            accuracy = float(tp + tn) / (tp + tn + fp + fn)
            accuracies.append(accuracy)
    else:
        threshold = thresholds
        idx1 = predictions > threshold
        idx2 = predictions <= threshold

        tp = 0
        fn = 0
        fp = 0
        tn = 0

        for i in range(num_pairs):
            pair_start = i * num_images_per_pair
            pair_end = (i + 1) * num_images_per_pair

            if np.all(labels[pair_start:pair_end] == 1):
                tp += np.sum(idx1[pair_start:pair_end])
                fn += np.sum(idx2[pair_start:pair_end])
            else:
                fp += np.sum(idx1[pair_start:pair_end])
                tn += np.sum(idx2[pair_start:pair_end])

        accuracy = float(tp + tn) / (tp + tn + fp + fn)
        accuracies.append(accuracy)

    return accuracies

# run this
predicted_distances = model.predict([X_test_pairs[:, 0, :, :, :], X_test_pairs[:, 1, :, :, :], X_test_pairs[:, 2, :, :, :], X_test_pairs[:, 3, :, :, :], X_test_pairs[:, 4, :, :, :]])
"""
thresholds = [0.10,0.15,0.20,0.23,0.25,0.30,0.35,0.40,0.42,0.45,0.47354182600975037
,0.50,0.51,0.52,0.535,0.55,0.60,0.65,0.67,0.70,0.75,0.80,0.85,0.87,0.89,0.90]
"""
thresholds = [0.10,0.15,0.20,0.23,0.25,0.30,0.35,0.40,0.42,0.45,0.47354182600975037,0.475,0.48,0.489
,0.50,0.51,0.52,0.535,0.55,0.60,0.62,0.65,0.659,0.67,0.70,0.75,0.80,0.85,0.87,0.89,0.90]

labels=Y_test_pairs
accuracies = compute_accuracy(predicted_distances, labels, thresholds)
for i in range(len(thresholds)):
  print("at threshold ",thresholds[i],"accuracy = ",accuracies[i])
plt.plot(thresholds, accuracies, marker='o')
plt.xlabel('Threshold')
plt.ylabel('Accuracy')
plt.title('Accuracy vs. Threshold')
plt.grid(True)
plt.show()



predictions = model.predict([img_A.reshape((1, 118, 118, 3)),
                        img_B.reshape((1, 118, 118, 3)),
                        img_C.reshape((1, 118, 118, 3)),
                        img_D.reshape((1, 118, 118, 3)),
                        img_E.reshape((1, 118, 118, 3))])

# The predictions will be an array of probabilities for each input
# If you want to convert the probabilities to binary predictions (0 or 1) based on a threshold, you can use:
binary_predictions = (predictions > 0.5).astype(int)
print(binary_predictions)
print(predictions)

difference_arr=[]
for i in range(len(X_test_pairs)-1):
  im=i
  img_A = imread(os.path.join(SIGN_PATH, test_df["GENUINE1"][im]))
  img_B = imread(os.path.join(SIGN_PATH, test_df["GENUINE2"][im]))
  img_C = imread(os.path.join(SIGN_PATH, test_df["GENUINE3"][im]))
  img_D = imread(os.path.join(SIGN_PATH, test_df["GENUINE4"][im]))
  img_E = imread(os.path.join(SIGN_PATH, test_df["TEST"][im]))
  label_A = y_test_arr[im]
  label_B = y_test_arr[im]
  label_C = y_test_arr[im]
  label_D = y_test_arr[im]
  label_E = y_test_arr[im]
  img_A = resize(img_A, (118, 118, 3))
  img_B = resize(img_B, (118, 118, 3))
  img_C = resize(img_C, (118, 118, 3))
  img_D = resize(img_D, (118, 118, 3))
  img_E = resize(img_E, (118, 118, 3))
  result = model.predict([img_A.reshape((1, 118, 118, 3)),
                        img_B.reshape((1, 118, 118, 3)),
                        img_C.reshape((1, 118, 118, 3)),
                        img_D.reshape((1, 118, 118, 3)),
                        img_E.reshape((1, 118, 118, 3))])
  difference_arr.append(result[0][0])

im=87
img_A = imread(os.path.join(SIGN_PATH, test_df["GENUINE1"][im]))
img_B = imread(os.path.join(SIGN_PATH, test_df["GENUINE2"][im]))
img_C = imread(os.path.join(SIGN_PATH, test_df["GENUINE3"][im]))
img_D = imread(os.path.join(SIGN_PATH, test_df["GENUINE4"][im]))
img_E = imread(os.path.join(SIGN_PATH, test_df["TEST"][im]))

label_A = y_test_arr[im]
label_B = y_test_arr[im]
label_C = y_test_arr[im]
label_D = y_test_arr[im]
label_E = y_test_arr[im]

img_A = resize(img_A, (118, 118, 3))
img_B = resize(img_B, (118, 118, 3))
img_C = resize(img_C, (118, 118, 3))
img_D = resize(img_D, (118, 118, 3))
img_E = resize(img_E, (118, 118, 3))

threshold1=0.60

import numpy as np

def compute_accuracy_custom(distanc_accs, labels):
  tn=0
  fn=0
  tp=0
  fp=0
  print(distanc_accs)
  print(labels)
  finalacc=0
  for i in range(len(labels)-1):
    if distanc_accs[i]==int(labels[i]):
      finalacc=finalacc+1
    if distanc_accs[i]== 0 and int(labels[i])==0:
      tn=tn+1
    elif distanc_accs[i]==1 and int(labels[i])==1:
      tp=tp+1
    elif distanc_accs[i]==1 and int(labels[i])==0:
      fp=fp+1
    elif distanc_accs[i]==0 and int(labels[i])==1:
      fn=fn+1
  finalacc/=len(labels)
  print("final accuracy is ", finalacc)
  print("TRUE POSITIVE RATE = ", tp)
  print("TRUE NEGATIVE RATE = ", tn)
  print("FALSE POSITIVE RATE = ", fp)
  print("FALSE NEGATIVE RATE = ", fn)
  return finalacc

final_acc=[]
for i in range (len(y_test_arr)-1):
  if difference_arr[i]>=threshold1:
    final_acc.append(0)
  elif difference_arr[i]<threshold1:
    final_acc.append(1)
final_acc_arr=np.array(final_acc)
print(final_acc_arr)
print(y_test_arr)
print(len(final_acc_arr))
print(len(y_test_arr))

compute_accuracy_custom(final_acc_arr,y_test_arr)

